{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlzheimerDataset(Dataset):\n",
    "    def __init__(self, images_filepaths, transform=None):\n",
    "        self.images_filepaths = images_filepaths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.images_filepaths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if os.path.normpath(image_filepath).split(os.sep)[-2] == \"Mild_Demented\":\n",
    "            label = 0\n",
    "        elif os.path.normpath(image_filepath).split(os.sep)[-2] == \"Moderate_Demented\":\n",
    "            label=1\n",
    "        elif os.path.normpath(image_filepath).split(os.sep)[-2] == \"Non_Demented\":\n",
    "            label=2\n",
    "        else:\n",
    "            label = 3\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install split-folders (记得安装)\n",
    "import splitfolders\n",
    "\n",
    "path='./Dataset'\n",
    "splitfolders.ratio(path,ratio=(0.7,0.3,0))\n",
    "# 拆分训练集,验证集，测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将train，validation的数据保存到output文件夹\n",
    "datasets={\n",
    "        'train':[],\n",
    "        'val':[]\n",
    "    }\n",
    "for phase in ['train','val']:\n",
    "    l=[]\n",
    "    for i in glob(f'./output/{phase}/**/*'):\n",
    "        l.append(i)\n",
    "    datasets[phase]=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对数据进行Augmentation处理\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=128, width=128),  # 调整图像大小为 128x128\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),  # 随机平移、缩放和旋转\n",
    "        A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),  # 随机RGB通道偏移\n",
    "        A.RandomBrightnessContrast(p=0.5),  # 随机亮度和对比度调整\n",
    "        A.ColorJitter(),  # 随机色彩抖动\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # 标准化\n",
    "        ToTensorV2(),  # 转换为PyTorch张量\n",
    "    ]\n",
    ")\n",
    "\n",
    "original_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(128, 128),  # 调整图像大小为 128x128\n",
    "        A.CenterCrop(height=128, width=128),  # 中心裁剪\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # 标准化\n",
    "        ToTensorV2(),  # 转换为PyTorch张量\n",
    "    ]\n",
    ")\n",
    "\n",
    "#创建实例\n",
    "alb_dataset = AlzheimerDataset(images_filepaths=datasets['train'], transform=train_transform)\n",
    "original_dataset=AlzheimerDataset(images_filepaths=datasets['train'], transform=original_transform)\n",
    "\n",
    "dataset_sizes = {x: len(datasets[x]) for x in ['train', 'val']}\n",
    "class_names = ['Mild_Demented','Moderate_Demented','Non_Demented','Very_Mild_Demented']\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存augmentation处理后的数据于predata文件夹\n",
    "import uuid\n",
    "try:\n",
    "    os.mkdir('./prepdata')\n",
    "    os.mkdir('./prepdata/train')\n",
    "    os.mkdir('./prepdata/train/Mild_Demented')\n",
    "    os.mkdir('./prepdata/train/Moderate_Demented')\n",
    "    os.mkdir('./prepdata/train/Non_Demented')\n",
    "    os.mkdir('./prepdata/train/Very_Mild_Demented')\n",
    "    \n",
    "except:\n",
    "    print('Files exist')\n",
    "\n",
    "def OriginalSave(originalDataset,limit):\n",
    "    s={0:'Mild_Demented',1:'Moderate_Demented',2:'Non_Demented',3:'Very_Mild_Demented'}\n",
    "    originalDataset.transform = A.Compose([t for t in originalDataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n",
    "    \n",
    "    for idx in range(limit):\n",
    "        image,label=originalDataset[idx]\n",
    "\n",
    "        cv2.imwrite(f'./prepdata/{s[label]}/{str(uuid.uuid4())}.jpg',image)\n",
    "OriginalSave(original_dataset, dataset_sizes['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance data\n",
    "def AlbSave(albDataset,limit):\n",
    "    s={0:'Mild_Demented',1:'Moderate_Demented',2:'Non_Demented',3:'Very_Mild_Demented'}\n",
    "    sizes={'Mild_Demented':896,'Moderate_Demented':64,'Non_Demented':3200,'Very_Mild_Demented':2240}\n",
    "\n",
    "    albDataset.transform = A.Compose([t for t in albDataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n",
    "    for idx in range(limit):\n",
    "        for _ in range(7):\n",
    "            image,label=albDataset[idx]\n",
    "            if label==0:\n",
    "                cv2.imwrite(f'./prepdata/train/{s[label]}/{str(uuid.uuid4())}.jpg',image)\n",
    "\n",
    "        for _ in range(100):\n",
    "            image,label=albDataset[idx]\n",
    "            if label==1:\n",
    "                cv2.imwrite(f'./prepdata/train/{s[label]}/{str(uuid.uuid4())}.jpg',image)\n",
    "\n",
    "        for _ in range(2):\n",
    "            image,label=albDataset[idx]\n",
    "            if label==2:\n",
    "                cv2.imwrite(f'./prepdata/train/{s[label]}/{str(uuid.uuid4())}.jpg',image)\n",
    "                \n",
    "        for _ in range(3):\n",
    "            image,label=albDataset[idx]\n",
    "            if label==3:\n",
    "                cv2.imwrite(f'./prepdata/train/{s[label]}/{str(uuid.uuid4())}.jpg',image)\n",
    "\n",
    "AlbSave(alb_dataset,dataset_sizes['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#不对验证集进行augmentation处理\n",
    "import shutil\n",
    "shutil.move('./output/val','./prepdata/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}